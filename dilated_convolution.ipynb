{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this code is to demonstrate that atrous convolution is not compute-heavy but memory-access limited on GPUs, explaining why such operations are challenging to optimize in CUDA."
      ],
      "metadata": {
        "id": "k8AVIJgYu4q9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dilated_convolution.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <cstdio>\n",
        "#include <cstdlib>\n",
        "\n",
        "#define CHECK_CUDA(call) \\\n",
        "    if ((call) != cudaSuccess) { \\\n",
        "        fprintf(stderr, \"CUDA error at %s:%d\\n\", __FILE__, __LINE__); \\\n",
        "        exit(1); \\\n",
        "    }\n",
        "\n",
        "\n",
        "__global__ void regular_access(const float* input, float* output, int N) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x; // global thread id\n",
        "    if (idx < N) {\n",
        "        output[idx] = input[idx] * 2.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void dilated_access(const float* input, float* output, int N, int stride) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int dilated_idx = idx * stride;\n",
        "\n",
        "    if (dilated_idx < N) {\n",
        "        output[dilated_idx] = input[dilated_idx] * 2.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 1 << 24;           // ~16 million elements\n",
        "    const int stride = 4;            // dilation factor\n",
        "    const int blockSize = 256;\n",
        "    const int gridSize = (N + blockSize - 1) / blockSize; //how many blocks we need\n",
        "\n",
        "    size_t bytes = N * sizeof(float); //Total memory size in bytes\n",
        "\n",
        "    // Host memory\n",
        "    float* h_input = (float*)malloc(bytes);\n",
        "    float* h_output = (float*)malloc(bytes);\n",
        "\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_input[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    // Device memory\n",
        "    float *d_input, *d_output;\n",
        "    // Allocate memory on the GPU\n",
        "    // Same size as host arrays\n",
        "    CHECK_CUDA(cudaMalloc(&d_input, bytes));\n",
        "    CHECK_CUDA(cudaMalloc(&d_output, bytes));\n",
        "\n",
        "    //copy input data from CPU to GPU\n",
        "    CHECK_CUDA(cudaMemcpy(d_input, h_input, bytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    CHECK_CUDA(cudaEventCreate(&start));\n",
        "    CHECK_CUDA(cudaEventCreate(&stop));\n",
        "\n",
        "    float ms;\n",
        "\n",
        "    CHECK_CUDA(cudaMemset(d_output, 0, bytes));\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    regular_access<<<gridSize, blockSize>>>(d_input, d_output, N);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&ms, start, stop);\n",
        "\n",
        "    printf(\"Regular access time:  %.3f ms\\n\", ms);\n",
        "\n",
        "    CHECK_CUDA(cudaMemset(d_output, 0, bytes));\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    dilated_access<<<gridSize, blockSize>>>(d_input, d_output, N, stride);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&ms, start, stop);\n",
        "\n",
        "    printf(\"Dilated access time (stride=%d): %.3f ms\\n\", stride, ms);\n",
        "\n",
        "    // Cleanup\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "    free(h_input);\n",
        "    free(h_output);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YQkux9VEffK",
        "outputId": "f3b63aff-c542-452d-c9fd-1d386c0a2a9b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dilated_convolution.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=native dilated_convolution.cu -o dilated_convolution"
      ],
      "metadata": {
        "id": "57a4gpP4FCaw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./dilated_convolution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggJmSAZAFiI2",
        "outputId": "681f8b26-46a4-4b3a-cef3-b157c7c54293"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regular access time:  0.606 ms\n",
            "Dilated access time (stride=4): 0.938 ms\n"
          ]
        }
      ]
    }
  ]
}